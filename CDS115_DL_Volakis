
!pip install git+https://github.com/openai/CLIP.git
!pip install torch
!pip install torch torchvision


# ===========================================
# Importing Necessary Libraries
# ===========================================

import numpy as np
import pickle
import torch
import clip
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from torch.utils.data import DataLoader, Dataset
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from google.colab import drive

# ===========================================
# Mount Google Drive
# ===========================================

drive.mount('/yourdrive', force_remount=True)
cifar100_path = '/yourpath'

# ===========================================
# Function to Load CIFAR-100 Data
# ===========================================

def load_cifar_file(filename):
    with open(filename, 'rb') as file:
        data = pickle.load(file, encoding='latin1')
    return data

# ===========================================
# Load the CIFAR-100 Dataset
# ===========================================

meta_data = load_cifar_file(cifar100_path + '/meta')
train_data = load_cifar_file(cifar100_path + '/train')
test_data = load_cifar_file(cifar100_path + '/test')

# Prepare the image data and labels
x_train = train_data['data'].reshape((-1, 32, 32, 3)).astype('float32') / 255
x_test = test_data['data'].reshape((-1, 32, 32, 3)).astype('float32') / 255
y_train = np.array(train_data['fine_labels'])
y_test = np.array(test_data['fine_labels'])

# ===========================================
# Selecting a Subset of 10 Classes
# ===========================================

# Choose 10 classes (update these indices to your preferred classes)
selected_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

# Filter the training and testing data to include only the selected classes
selected_indices_train = np.isin(y_train, selected_classes)
selected_indices_test = np.isin(y_test, selected_classes)

x_train = x_train[selected_indices_train]
y_train = y_train[selected_indices_train]
x_test = x_test[selected_indices_test]
y_test = y_test[selected_indices_test]

# ===========================================
# Define and Train the Autoencoder
# ===========================================

def build_autoencoder(img_shape):
    input_img = Input(shape=img_shape)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
    encoded = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)
    autoencoder = Model(input_img, decoded)
    encoder = Model(input_img, encoded)
    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
    return autoencoder, encoder

autoencoder, encoder = build_autoencoder((32, 32, 3))
autoencoder.fit(x_train, x_train, epochs=10, batch_size=256, shuffle=True, validation_data=(x_test, x_test))

# ===========================================
# Generate Encoded Features using Autoencoder
# ===========================================

encoded_imgs_train = encoder.predict(x_train)
encoded_imgs_test = encoder.predict(x_test)

# Flatten the encoded images
encoded_imgs_train_flat = encoded_imgs_train.reshape((encoded_imgs_train.shape[0], -1))
encoded_imgs_test_flat = encoded_imgs_test.reshape((encoded_imgs_test.shape[0], -1))

# Normalize the features
scaler = StandardScaler()
encoded_imgs_train_flat = scaler.fit_transform(encoded_imgs_train_flat)
encoded_imgs_test_flat = scaler.transform(encoded_imgs_test_flat)

# ===========================================
# Train and Evaluate the 3-NN Classifier on Autoencoder Features
# ===========================================

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(encoded_imgs_train_flat, y_train.ravel())
y_pred = knn.predict(encoded_imgs_test_flat)
accuracy_autoencoder = accuracy_score(y_test, y_pred)
print(f'Accuracy with Autoencoder Features: {accuracy_autoencoder}')

# ===========================================
# Train and Evaluate the 3-NN Classifier on Original Features
# ===========================================

# Flatten the original images
x_train_flat = x_train.reshape((x_train.shape[0], -1))
x_test_flat = x_test.reshape((x_test.shape[0], -1))

# Normalize the original features
x_train_flat = scaler.fit_transform(x_train_flat)
x_test_flat = scaler.transform(x_test_flat)

# Train and evaluate the 3-NN classifier on the original features
knn_original = KNeighborsClassifier(n_neighbors=3)
knn_original.fit(x_train_flat, y_train.ravel())
y_pred_original = knn_original.predict(x_test_flat)
accuracy_original = accuracy_score(y_test, y_pred_original)
print(f'Accuracy with Original Features: {accuracy_original}')

# ===========================================
# Generate and Evaluate CLIP Embeddings
# ===========================================

# Load the CLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# Function to preprocess images and generate CLIP embeddings
def generate_clip_embeddings(images):
    embeddings = []
    for img in images:
        img = Image.fromarray((img * 255).astype(np.uint8))  # Convert numpy array to PIL Image
        img = preprocess(img).unsqueeze(0).to(device)  # Preprocess and add batch dimension
        with torch.no_grad():
            img_features = model.encode_image(img)
        embeddings.append(img_features.cpu().numpy().flatten())
    return np.array(embeddings)

# Generate CLIP embeddings for training and testing data
clip_train_embeds = generate_clip_embeddings(x_train)
clip_test_embeds = generate_clip_embeddings(x_test)

# Normalize the CLIP embeddings
clip_train_embeds = scaler.fit_transform(clip_train_embeds)
clip_test_embeds = scaler.transform(clip_test_embeds)

# Train and evaluate the 3-NN classifier on CLIP embeddings
knn_clip = KNeighborsClassifier(n_neighbors=3)
knn_clip.fit(clip_train_embeds, y_train.ravel())
y_pred_clip = knn_clip.predict(clip_test_embeds)
accuracy_clip = accuracy_score(y_test, y_pred_clip)
print(f'Accuracy with CLIP Embeddings: {accuracy_clip}')

# ===========================================
# Generate and Evaluate ResNet Embeddings
# ===========================================

# Define a custom dataset class for CIFAR-100 data
class CIFAR100Dataset(Dataset):
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

# Define transformations for the ResNet model (resize and normalization)
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize(224),  # ResNet expects 224x224 images
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Create datasets and dataloaders
train_dataset = CIFAR100Dataset(x_train, y_train, transform=transform)
test_dataset = CIFAR100Dataset(x_test, y_test, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=256, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)

# Load a pre-trained ResNet model
resnet = models.resnet50(pretrained=True)
resnet = resnet.to(device)
resnet.eval()

# Remove the final fully connected layer to get embeddings
resnet = torch.nn.Sequential(*(list(resnet.children())[:-1]))

# Function to generate ResNet embeddings
def generate_resnet_embeddings(dataloader):
    embeddings = []
    with torch.no_grad():
        for images, _ in dataloader:
            images = images.to(device)
            features = resnet(images)
            features = features.view(features.size(0), -1)  # Flatten the features
            embeddings.append(features.cpu().numpy())
    return np.vstack(embeddings)

# Generate ResNet embeddings for training and testing data
resnet_train_embeds = generate_resnet_embeddings(train_loader)
resnet_test_embeds = generate_resnet_embeddings(test_loader)

# Normalize the ResNet embeddings
resnet_train_embeds = scaler.fit_transform(resnet_train_embeds)
resnet_test_embeds = scaler.transform(resnet_test_embeds)

# Train and evaluate the 3-NN classifier on ResNet embeddings
knn_resnet = KNeighborsClassifier(n_neighbors=3)
knn_resnet.fit(resnet_train_embeds, y_train.ravel())
y_pred_resnet = knn_resnet.predict(resnet_test_embeds)
accuracy_resnet = accuracy_score(y_test, y_pred_resnet)
print(f'Accuracy with ResNet Embeddings: {accuracy_resnet}')

# ===========================================
# Generalization Function for Any Subset of 10 Classes
# ===========================================

def train_and_evaluate_for_classes(selected_classes):
    selected_indices_train = np.isin(y_train, selected_classes)
    selected_indices_test = np.isin(y_test, selected_classes)

    x_train_selected = x_train[selected_indices_train]
    y_train_selected = y_train[selected_indices_train]
    x_test_selected = x_test[selected_indices_test]
    y_test_selected = y_test[selected_indices_test]

    # Repeat the steps for autoencoder, original features, CLIP, and other embeddings
    # ... (The same steps as above for training and evaluation)

    return accuracy_autoencoder, accuracy_original, accuracy_clip, accuracy_resnet

# Example usage with 10 selected classes
selected_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # Replace with any 10 class indices
accuracies = train_and_evaluate_for_classes(selected_classes)
